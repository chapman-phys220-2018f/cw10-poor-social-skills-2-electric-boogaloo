{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Ordinary Differential Equation Methods\n",
    "Trevor Kling\n",
    "11/2/2018\n",
    "### Introduction\n",
    "In this module, the differences and benefits of various methods of computing ordinary differential equations are explored.  The module analyzes five methods: the Euler method, the Leapfrog method, Heun's method, and the Second- and Fourth-Order Runge-Kutta methods.  Each example considers an ordinary differential equation, written as $$u'(t) = f[t, u(t)]$$  Effectively, the function $f[t, u(t)]$ represents the slope of the function $u(t)$ at some specific value of $t$.  A set of $t$ values with uniform spacing $\\Delta t$ are then selected from a range $[t, t_N]$ and used to construct a matching set of uniformly generated $u$ values; this results in the sets $(t_0, t_1, ..., t_N)$ and $(u_0, u_1, ..., u_N)$.  Choosing some starting value as $u_k$, these values are then used to calculate an approximation of the next value $u_{k+1}$.\n",
    "### Euler's Method\n",
    "Euler's method is the most straight-forward of the methods discussed, but also the most inaccurate.  The formula for Euler's method is as follows: $$ u_{k+1} = u_k + \\Delta t\\, f[t_k, u_k] $$  In this approach, $f[t_k, u_k]$ represents the slope of the function $u$ at the point $t$. This slope defines a line, and the approximation of the new  point becomes the initial value of the function $u_k$ shifted along this line by a value $\\Delta t$.  The issues of this method appear when considering multiple sequential applications; each time, the method will approximate a value slightly off of the actual value of the function.  Because the starting point for the next approximation is whatever the previous function generated, any degree of divergence from previous results is retained by the new approximation.  Thus, functions which do not alternate between positive and negative slope values will find that the approximation quickly diverges from the actual value.  For this reason, Euler's method is only accurate up to the first order of a differential equation.  Euler's method is analagous to the forward difference method of approximating a derivative, and is less precise than any of the other methods discussed.\n",
    "### Leapfrog Method\n",
    "As Euler's method is analagous to the forward difference, the leapfrog method is analagous to the center differnce approxiamtion of a derivative.  Thus, just as with a normal derivative, it results in more precision than its predecessor.  The leapfrog method is given by $$ u_{k+1} = u_{k-1} + 2\\Delta t\\, f[t_k, u_k] $$  In this case, the funciton uses the previous value of $u$ and shifts that value along the tangent line by $2 \\Delta t$ to find the next value of $u$.  This method comes with an inherit problem however, in that it can only calculate center values.  $u_0$ to $u_1$ must still be computed with Euler's method, as there is no $u_{-1}$.  Regardless, this method results in less error than Euler's Method for interior points.  This greater degree of accuracy allows for this method to be used up to second order differenctial equations.\n",
    "### Heun's Method\n",
    "Heun's method is the first method investigated to feature more than one equation.  Heun's Method, also called the Trapezoid method, is given by the following equations: $$\\tilde{u}_{k+1} = u_k + \\Delta t\\, f[t_k, u_k] \\\\ u_{k+1} = u_k + (\\Delta t/2)(f[t_k, u_k] + f[t_{k+1}, \\tilde{u}_{k+1}])$$  In this case, the average of the current point's and the next approximation's slopes is used, instead of simply using the slope of a single point.  The approximation of the next point is first calculated using Euler's method, then is corrected based on the slope of the current point.  The general idea is that a slope of the next point will overestimate when the previous point underestimates, and vice versa.  Thus, by averaging the two, the result becomes more accurate.  Like the leapfrog method, this result is accurate to the second order.\n",
    "### Second-Order Runge-Kutta Method\n",
    "Similarly to Heun's Method, the second-order Runge-Kutta method is accurate to the second order.  However, this method utilizes the notion of a midpoint instead of two distal points.  The method is described by the following three equations:\n",
    "   $$u_{k+1} = u_k + K_2 \\\\\n",
    "   K_1 = \\Delta t\\, f[t_k, u_k] \\\\\n",
    "   K_2 = \\Delta t\\, f[t_k + \\Delta t/2, u_k + K_1/2]$$\n",
    "The method starts by calculating an offset of the original point by its original slope, $K_1$.  Half of this offset is then used to create a new midpoint $u_k + K_1/2$, and subsequently the slope at that point is used to find the approximation of the new point.\n",
    "### Fourth-Order Runge-Kutta Method\n",
    "The Fourth-Order Runge-Kutta method follows a very similar pattern to that of the Second-Order variation:\n",
    "$$u_{k+1} = u_k + (K_1 + 2K_2 + 2K_3 + K_4)/6 \\\\\n",
    "K_1 = \\Delta t\\,f[t_k,u_k] \\\\\n",
    "K_2 = \\Delta t\\, f[t_k + \\Delta t/2, u_k + K_1/2] \\\\\n",
    "K_3 = \\Delta t\\, f[t_k + \\Delta t/2, u_k + K_2/2] \\\\\n",
    "K_4 = \\Delta t\\,f[t_k + \\Delta t, u_k + K_3]$$\n",
    "The method now caclulates the slope at four separate points.  The first approximation is made using the slope of the original point, forming the offset $K_1$.  Half this offset is added to the original point, and the new midpoint has its slope evaluated for the offset $K_2$.  The method then takes a second midpoint by using the slope of the approximated midpoint to offset the original point.  This forms another midpoint, which has its slope evaluated for offset $K_3$.  This offset $K_3$ is then used to find an approximation of the slope at the end point, $K_4$.  These slopes are then subject to a weighted average, in which the midpoint displacements are given more weight than the edge cases.  This average is then used to find the approximation of the new point.  Of the methods discussed thus far, the Fourth-Order Runge-Kutta method is by far the most accurate, and is reliable up to the fourth order.  Additionally, by adding more iterations of $K_n$, one can extend this method to the $n$th order.  However, the Fourth-Order method is the most commonly used, as it provides the greatest degree of accuracy for computational time."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Anaconda 5)",
   "language": "python",
   "name": "anaconda5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}